name: generate_boolean_questions
description: Generates boolean questions about a chunk of text.
template: |
  Help prepare QnA pairs with short answers for a topic by extracting them from the given text.
  Try to keep the answer as short as possible, it should contain one factoid based on the provided text.
  Output must list the specified number of statements in JSON.

  <|separator|>
  Text:
  <|text_start|>
  LLMs are resource-intensive, both in terms of computing power and API costs. If you
  don't need an LLM or can achieve the same result with a smaller model, I recommend doing
  so. If you still decide to build an LLM-based application, I highly recommend monitoring
  API usage and costs closely.
  <|text_end|>
  Output with 4 QnA pairs with short answers:
  <|separator|>
  
  [Q]: What's a challenge with LLMs?
  [A]: They are resource-intensive
  [Q]: What types of language models can you use in your application?
  [A]: Both small and large language models work.
  [Q]: What sort of monitoring is recommended for LLM-based applications?
  [A]: Cost and usage monitoring is recommended.
  [Q]: When are LLMs recommended?
  [A]: When you don't have other language-based options to process the data.
  <|separator|>
  
  Text:
  <|text_start|>
  {{context}}
  <|text_end|>
  Output with {{count}} QnA pairs with short answers:  
template_format: handlebars
input_variables:
  - name: context
    description: The topic to generate QnA pairs for.
    is_required: true
execution_settings:
  default:
    top_p: 0.98
    temperature: 0.7
    presence_penalty: 0.0
    frequency_penalty: 0.0
    max_tokens: 1200